from jet.adapters.langchain.chat_ollama import ChatOllama
from jet.logger import logger
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.tools.riza.command import ExecPython
from langchain_core.prompts import ChatPromptTemplate
import os
import shutil


OUTPUT_DIR = os.path.join(
    os.path.dirname(__file__), "generated", os.path.splitext(os.path.basename(__file__))[0])
shutil.rmtree(OUTPUT_DIR, ignore_errors=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
log_file = os.path.join(OUTPUT_DIR, "main.log")
logger.basicConfig(filename=log_file)
logger.info(f"Logs: {log_file}")

PERSIST_DIR = f"{OUTPUT_DIR}/chroma"
os.makedirs(PERSIST_DIR, exist_ok=True)

"""
# Riza Code Interpreter

> The Riza Code Interpreter is a WASM-based isolated environment for running Python or JavaScript generated by AI agents.

In this notebook we'll create an example of an agent that uses Python to solve a problem that an LLM can't solve on its own:
counting the number of 'r's in the word "strawberry."

Before you get started grab an API key from the [Riza dashboard](https://dashboard.riza.io). For more guides and a full API reference
head over to the [Riza Code Interpreter API documentation](https://docs.riza.io).

Make sure you have the necessary dependencies installed.
"""
logger.info("# Riza Code Interpreter")

# %pip install --upgrade --quiet langchain-community rizaio

"""
Set up your API keys as an environment variable.
"""
logger.info("Set up your API keys as an environment variable.")

# %env ANTHROPIC_API_KEY=<your_anthropic_api_key_here>
# %env RIZA_API_KEY=<your_riza_api_key_here>



"""
Initialize the `ExecPython` tool.
"""
logger.info("Initialize the `ExecPython` tool.")

tools = [ExecPython()]

"""
Initialize an agent using Ollama's Claude Haiku model.
"""
logger.info("Initialize an agent using Ollama's Claude Haiku model.")

llm = ChatOllama(model="llama3.2")

prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Make sure to use a tool if you need to solve a problem.",
        ),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

agent = create_tool_calling_agent(llm, tools, prompt_template)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

result = agent_executor.invoke({"input": "how many rs are in strawberry?"})
logger.debug(result["output"][0]["text"])

logger.info("\n\n[DONE]", bright=True)