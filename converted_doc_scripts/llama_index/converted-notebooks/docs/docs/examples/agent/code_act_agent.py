import asyncio
from jet.transformers.formatters import format_json
from jet.llm.mlx.base import MLX
from jet.logger import CustomLogger
from jet.models.config import MODELS_CACHE_DIR
from llama_index.core.agent.workflow import (
ToolCall,
ToolCallResult,
AgentStream,
)
from llama_index.core.agent.workflow import CodeActAgent
from llama_index.core.settings import Settings
from llama_index.core.workflow import Context
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from typing import Any, Dict, Tuple
import ast
import contextlib
import io
import os
import shutil
import traceback


OUTPUT_DIR = os.path.join(
    os.path.dirname(__file__), "generated", os.path.splitext(os.path.basename(__file__))[0])
shutil.rmtree(OUTPUT_DIR, ignore_errors=True)
log_file = os.path.join(OUTPUT_DIR, "main.log")
logger = CustomLogger(log_file, overwrite=True)
logger.info(f"Logs: {log_file}")

model_name = "sentence-transformers/all-MiniLM-L6-v2"
Settings.embed_model = HuggingFaceEmbedding(
    model_name=model_name,
    cache_folder=MODELS_CACHE_DIR,
)


"""
# Prebuilt CodeAct Agent w/ LlamaIndex

LlamaIndex offers a prebuilt CodeAct Agent that can be used to write and execute code, inspired by the original [CodeAct paper](https://arxiv.org/abs/2402.01030).

With this agent, you provide an agent with a set of functions, and the agent will write code that uses those functions to help complete the task you give it.

Some advantages of using the CodeAct Agent:

- No need to exhaustively list out all the possible functions that the agent might need
- The agent can develop complex workflows around your existing functions
- Can integrate directly with existing API's

Let's walk through a simple example of how to use the CodeAct Agent.

**NOTE:** This example includes code that will execute arbitrary code. This is dangerous, and proper sandboxing should be used in production environments.

## Setup

First, let's configure the LLM we want to use, and provide some functions that we can use in our code.
"""
logger.info("# Prebuilt CodeAct Agent w/ LlamaIndex")

# %pip install -U llama-index-core llama-index-llms-ollama


llm = MLX(model="qwen3-1.7b-4bit-mini", api_key="sk-...")


def add(a: int, b: int) -> int:
    """Add two numbers together"""
    return a + b


def subtract(a: int, b: int) -> int:
    """Subtract two numbers"""
    return a - b


def multiply(a: int, b: int) -> int:
    """Multiply two numbers"""
    return a * b


def divide(a: int, b: int) -> float:
    """Divide two numbers"""
    return a / b

"""
## Create a Code Executor 

The `CodeActAgent` will require a specific `code_execute_fn` to execute the code generated by the agent.

Below, we define a simple `code_execute_fn` that will execute the code in-process and maintain execution state.

**NOTE:** In a production environment, you should use a more robust method of executing code. This is just for demonstration purposes, and executing code in-process is dangerous. Consider using docker or external services to execute code.

With this executor, we can pass in a dictionary of local and global variables to use in the execution context.

- `locals`: Local variables to use in the execution context, this includes our functions that we want the LLM to code around
- `globals`: Global variables to use in the execution context, this includes the builtins and other imported modules we want to use in the execution context
"""
logger.info("## Create a Code Executor")



class SimpleCodeExecutor:
    """
    A simple code executor that runs Python code with state persistence.

    This executor maintains a global and local state between executions,
    allowing for variables to persist across multiple code runs.

    NOTE: not safe for production use! Use with caution.
    """

    def __init__(self, locals: Dict[str, Any], globals: Dict[str, Any]):
        """
        Initialize the code executor.

        Args:
            locals: Local variables to use in the execution context
            globals: Global variables to use in the execution context
        """
        self.globals = globals
        self.locals = locals

    def execute(self, code: str) -> Tuple[bool, str, Any]:
        """
        Execute Python code and capture output and return values.

        Args:
            code: Python code to execute

        Returns:
            Dict with keys `success`, `output`, and `return_value`
        """
        stdout = io.StringIO()
        stderr = io.StringIO()

        output = ""
        return_value = None
        try:
            with contextlib.redirect_stdout(
                stdout
            ), contextlib.redirect_stderr(stderr):
                try:
                    tree = ast.parse(code)
                    last_node = tree.body[-1] if tree.body else None

                    if isinstance(last_node, ast.Expr):
                        last_line = code.rstrip().split("\n")[-1]
                        exec_code = (
                            code[: -len(last_line)]
                            + "\n__result__ = "
                            + last_line
                        )

                        exec(exec_code, self.globals, self.locals)
                        return_value = self.locals.get("__result__")
                    else:
                        exec(code, self.globals, self.locals)
                except:
                    exec(code, self.globals, self.locals)

            output = stdout.getvalue()
            if stderr.getvalue():
                output += "\n" + stderr.getvalue()

        except Exception as e:
            output = f"Error: {type(e).__name__}: {str(e)}\n"
            output += traceback.format_exc()

        if return_value is not None:
            output += "\n\n" + str(return_value)

        return output

code_executor = SimpleCodeExecutor(
    locals={
        "add": add,
        "subtract": subtract,
        "multiply": multiply,
        "divide": divide,
    },
    globals={
        "__builtins__": __builtins__,
        "np": __import__("numpy"),
    },
)

"""
## Setup the CodeAct Agent

Now that we have our code executor, we can setup the CodeAct Agent.
"""
logger.info("## Setup the CodeAct Agent")


agent = CodeActAgent(
    code_execute_fn=code_executor.execute,
    llm=llm,
    tools=[add, subtract, multiply, divide],
)

ctx = Context(agent)

"""
## Use the Agent

Now that we have our agent, we can use it to complete tasks! Since we gave it some math functions, we will prompt it for tasks that require calculations.
"""
logger.info("## Use the Agent")



async def run_agent_verbose(agent, ctx, query):
    handler = agent.run(query, ctx=ctx)
    logger.debug(f"User:  {query}")
    async for event in handler.stream_events():
        if isinstance(event, ToolCallResult):
            logger.debug(
                f"\n-----------\nCode execution result:\n{event.tool_output}"
            )
        elif isinstance(event, ToolCall):
            logger.debug(f"\n-----------\nParsed code:\n{event.tool_kwargs['code']}")
        elif isinstance(event, AgentStream):
            logger.debug(f"{event.delta}", end="", flush=True)

    async def run_async_code_745df5ad():
        return await handler
        return 
     = asyncio.run(run_async_code_745df5ad())
    logger.success(format_json())

"""
Here, the agent uses some built-in functions to calculate the sum of all numbers from 1 to 10.
"""
logger.info("Here, the agent uses some built-in functions to calculate the sum of all numbers from 1 to 10.")

async def async_func_0():
    response = await run_agent_verbose(
        agent, ctx, "Calculate the sum of all numbers from 1 to 10"
    )
    return response
response = asyncio.run(async_func_0())
logger.success(format_json(response))

"""
Next, we get the agent to use the tools that we passed in.
"""
logger.info("Next, we get the agent to use the tools that we passed in.")

async def async_func_0():
    response = await run_agent_verbose(
        agent, ctx, "Add 5 and 3, then multiply the result by 2"
    )
    return response
response = asyncio.run(async_func_0())
logger.success(format_json(response))

"""
We can even get the agent to define new functions for us!
"""
logger.info("We can even get the agent to define new functions for us!")

async def async_func_0():
    response = await run_agent_verbose(
        agent, ctx, "Calculate the sum of the first 10 fibonacci numbers"
    )
    return response
response = asyncio.run(async_func_0())
logger.success(format_json(response))

"""
And then reuse those new functions in a new task!
"""
logger.info("And then reuse those new functions in a new task!")

async def async_func_0():
    response = await run_agent_verbose(
        agent, ctx, "Calculate the sum of the first 20 fibonacci numbers"
    )
    return response
response = asyncio.run(async_func_0())
logger.success(format_json(response))

logger.info("\n\n[DONE]", bright=True)