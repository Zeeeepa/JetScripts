{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8761049",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llama_dataset/labelled-rag-datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481b689-d363-40a9-a8a4-7d8c6a3a67bd",
   "metadata": {},
   "source": [
    "# Benchmarking RAG Pipelines With A `LabelledRagDatatset`\n",
    "\n",
    "The `LabelledRagDataset` is meant to be used for evaluating any given RAG pipeline, for which there could be several configurations (i.e. choosing the `LLM`, values for the `similarity_top_k`, `chunk_size`, and others). We've likened this abstract to traditional machine learning datastets, where `X` features are meant to predict a ground-truth label `y`. In this case, we use the `query` as well as the retrieved `contexts` as the \"features\" and the answer to the query, called `reference_answer` as the ground-truth label.\n",
    "\n",
    "And of course, such datasets are comprised of observations or examples. In the case of `LabelledRagDataset`, these are made up with a set of `LabelledRagDataExample`'s.\n",
    "\n",
    "In this notebook, we will show how one can construct a `LabelledRagDataset` from scratch. Please note that the alternative to this would be to simply download a community supplied `LabelledRagDataset` from `llama-hub` in order to evaluate/benchmark your own RAG pipeline on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d14822-2779-4da9-bfb7-201f361b8eb1",
   "metadata": {},
   "source": [
    "### The `LabelledRagDataExample` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d66982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-llms-openai\n",
    "# %pip install llama-index-readers-wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a22a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08725cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_Settings(_llm=Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x16352f1d0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x1425f9ee0>, completion_to_prompt=<function default_completion_to_prompt at 0x142841a80>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.1', temperature=0.0, context_window=4096, request_timeout=300.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None), _embed_model=OllamaEmbedding(model_name='mxbai-embed-large', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x16352f1d0>, num_workers=None, base_url='http://localhost:11434', ollama_additional_kwargs={}), _callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x16352f1d0>, _tokenizer=None, _node_parser=SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x16352f1d0>, id_func=<function default_id_func at 0x1428de520>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?'), _prompt_helper=None, _transformations=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jet.llm.ollama import initialize_ollama_settings, create_llm\n",
    "initialize_ollama_settings({\n",
    "    \"embedding_model\": \"mxbai-embed-large\",\n",
    "    \"chunk_size\": 1024,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5017a52c-e61b-4172-b996-c7d7ce56c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import (\n",
    "    LabelledRagDataExample,\n",
    "    CreatedByType,\n",
    "    CreatedBy,\n",
    ")\n",
    "\n",
    "# constructing a LabelledRagDataExample\n",
    "query = \"This is a test query, is it not?\"\n",
    "query_by = CreatedBy(type=CreatedByType.AI, model_name=\"llama3.1\")\n",
    "reference_answer = \"Yes it is.\"\n",
    "reference_answer_by = CreatedBy(type=CreatedByType.HUMAN)\n",
    "reference_contexts = [\"This is a sample context\"]\n",
    "\n",
    "rag_example = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295953f-bbe1-4cc2-8a60-1eb75678d57e",
   "metadata": {},
   "source": [
    "The `LabelledRagDataExample` is a Pydantic `Model` and so, going from `json` or `dict` (and vice-versa) is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bffa5b37-4453-49c4-8527-9a5c772dd436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\":\"This is a test query, is it not?\",\"query_by\":{\"model_name\":\"llama3.1\",\"type\":\"ai\"},\"reference_contexts\":[\"This is a sample context\"],\"reference_answer\":\"Yes it is.\",\"reference_answer_by\":{\"model_name\":\"\",\"type\":\"human\"}}\n"
     ]
    }
   ],
   "source": [
    "print(rag_example.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86da0f2-c11b-41b1-bfe7-8c5be9f51a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query='This is a test query, is it not?', query_by=CreatedBy(model_name='llama3.1', type=<CreatedByType.AI: 'ai'>), reference_contexts=['This is a sample context'], reference_answer='Yes it is.', reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelledRagDataExample.parse_raw(rag_example.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23231be-6cc1-49f7-81e9-b2721d1ac836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'This is a test query, is it not?',\n",
       " 'query_by': {'model_name': 'llama3.1', 'type': <CreatedByType.AI: 'ai'>},\n",
       " 'reference_contexts': ['This is a sample context'],\n",
       " 'reference_answer': 'Yes it is.',\n",
       " 'reference_answer_by': {'model_name': '',\n",
       "  'type': <CreatedByType.HUMAN: 'human'>}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_example.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3040e95-d459-4193-8c45-5238001f1da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query='This is a test query, is it not?', query_by=CreatedBy(model_name='llama3.1', type=<CreatedByType.AI: 'ai'>), reference_contexts=['This is a sample context'], reference_answer='Yes it is.', reference_answer_by=CreatedBy(model_name='', type=<CreatedByType.HUMAN: 'human'>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelledRagDataExample.parse_obj(rag_example.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97213dd9-c828-4781-af09-c690d9234103",
   "metadata": {},
   "source": [
    "Let's create a second example, so we can have a (slightly) more interesting `LabelledRagDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1986f16f-3f80-4c22-89a0-4d9fa1475d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"This is a test query, is it so?\"\n",
    "reference_answer = \"I think yes, it is.\"\n",
    "reference_contexts = [\"This is a second sample context\"]\n",
    "\n",
    "rag_example_2 = LabelledRagDataExample(\n",
    "    query=query,\n",
    "    query_by=query_by,\n",
    "    reference_contexts=reference_contexts,\n",
    "    reference_answer=reference_answer,\n",
    "    reference_answer_by=reference_answer_by,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709422c5-8d1d-462a-bfe8-2eabc73c077f",
   "metadata": {},
   "source": [
    "### The `LabelledRagDataset` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2750320c-ae60-455b-a79c-e8774bf4fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "\n",
    "rag_dataset = LabelledRagDataset(examples=[rag_example, rag_example_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2812220-f176-49bd-af7c-9a01c3a2dd2a",
   "metadata": {},
   "source": [
    "There exists a convienience method to view the dataset as a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1511ddc-c0ed-4aeb-9ff8-76b090d54dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test query, is it not?</td>\n",
       "      <td>[This is a sample context]</td>\n",
       "      <td>Yes it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a test query, is it so?</td>\n",
       "      <td>[This is a second sample context]</td>\n",
       "      <td>I think yes, it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query                 reference_contexts  \\\n",
       "0  This is a test query, is it not?         [This is a sample context]   \n",
       "1   This is a test query, is it so?  [This is a second sample context]   \n",
       "\n",
       "      reference_answer reference_answer_by       query_by  \n",
       "0           Yes it is.               human  ai (llama3.1)  \n",
       "1  I think yes, it is.               human  ai (llama3.1)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f541811-043f-4065-9905-0734173f329f",
   "metadata": {},
   "source": [
    "#### Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63716f0-7723-4f21-9f80-703b257f8b48",
   "metadata": {},
   "source": [
    "To persist and load the dataset to and from disk, there are the `save_json` and `from_json` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3a2781-b4c4-49e6-8245-e2381aacc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6400b2c3-5b49-40c2-897b-ac3819beb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_rag_dataset = LabelledRagDataset.from_json(\"rag_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111e13eb-120a-434c-a04b-5c0b9fdcd60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a test query, is it not?</td>\n",
       "      <td>[This is a sample context]</td>\n",
       "      <td>Yes it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a test query, is it so?</td>\n",
       "      <td>[This is a second sample context]</td>\n",
       "      <td>I think yes, it is.</td>\n",
       "      <td>human</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              query                 reference_contexts  \\\n",
       "0  This is a test query, is it not?         [This is a sample context]   \n",
       "1   This is a test query, is it so?  [This is a second sample context]   \n",
       "\n",
       "      reference_answer reference_answer_by       query_by  \n",
       "0           Yes it is.               human  ai (llama3.1)  \n",
       "1  I think yes, it is.               human  ai (llama3.1)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload_rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f98e8-239a-4007-8754-5a9b4edb41a4",
   "metadata": {},
   "source": [
    "### Building a synthetic `LabelledRagDataset` over Wikipedia \n",
    "\n",
    "For this section, we'll first create a `LabelledRagDataset` using a synthetic generator. Ultimately, we will use GPT-4 to produce both the `query` and `reference_answer` for the synthetic `LabelledRagDataExample`'s.\n",
    "\n",
    "NOTE: if one has queries, reference answers, and contexts over a text corpus, then it is not necessary to use data synthesis to be able to predict and subsequently evaluate said predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cdd40c6-9912-4a2d-bb12-654e1784da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbebaa77-45a0-45d3-8fb8-8570d5c6c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia pages\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "\n",
    "# cities = [\n",
    "#     \"San Francisco\",\n",
    "# ]\n",
    "# documents = WikipediaReader().load_data(\n",
    "#     pages=[f\"History of {x}\" for x in cities]\n",
    "# )\n",
    "context_files = [\n",
    "    \"/Users/jethroestrada/Desktop/External_Projects/AI/chatbot/open-webui/backend/crewAI/docs/installation.mdx\",\n",
    "    \"/Users/jethroestrada/Desktop/External_Projects/AI/chatbot/open-webui/backend/crewAI/docs/introduction.mdx\",\n",
    "    \"/Users/jethroestrada/Desktop/External_Projects/AI/chatbot/open-webui/backend/crewAI/docs/quickstart.mdx\",\n",
    "]\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=context_files,\n",
    ").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf0412f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c6567-b420-4d5c-a022-dfb4889da795",
   "metadata": {},
   "source": [
    "The `RagDatasetGenerator` can be built over a set of documents to generate `LabelledRagDataExample`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f930d75-7a93-4d4c-a647-5f8eeefe37ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c1cc2fd4b74533aff15abf43254bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate questions against chunks\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "\n",
    "# set context for llm provider\n",
    "llm = create_llm(model=\"llama3.1\", temperature=0.3)\n",
    "num_questions_per_chunk = 2\n",
    "\n",
    "# instantiate a DatasetGenerator\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    num_questions_per_chunk=num_questions_per_chunk,  # set the number of questions per nodes\n",
    "    show_progress=True,\n",
    "    question_gen_query=f\"You are a Senior Programmer. Your task is to setup {num_questions_per_chunk} questions about features or code implementation. Restrict the questions to the context information provided.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf592778-a914-4bbf-a88b-3bbc715d70d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_generator.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d09fbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='58a6d2e3-bd00-4ea1-ab39-8f2326a05b34', embedding=None, metadata={'file_path': '/Users/jethroestrada/Desktop/External_Projects/AI/chatbot/open-webui/backend/crewAI/docs/installation.mdx', 'file_name': 'installation.mdx', 'file_size': 4038, 'creation_date': '2024-12-10', 'last_modified_date': '2024-12-10'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='88a55a18-9f48-4649-b538-2a97fad2cf7b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/jethroestrada/Desktop/External_Projects/AI/chatbot/open-webui/backend/crewAI/docs/installation.mdx', 'file_name': 'installation.mdx', 'file_size': 4038, 'creation_date': '2024-12-10', 'last_modified_date': '2024-12-10'}, hash='b45d6db83a49cb34c78f78712eac27ec56557d00fe6bee43f5ebbbd603afc232')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='---\\ntitle: Installation\\ndescription: Get started with CrewAI - Install, configure, and build your first AI crew\\nicon: wrench\\n---\\n\\n<Note>\\n  **Python Version Requirements**\\n  \\n  CrewAI requires `Python >=3.10 and <=3.12`. Here\\'s how to check your version:\\n  ```bash\\n  python3 --version\\n  ```\\n  \\n  If you need to update Python, visit [python.org/downloads](https://python.org/downloads)\\n</Note>\\n\\n# Installing CrewAI\\n\\nCrewAI is a flexible and powerful AI framework that enables you to create and manage AI agents, tools, and tasks efficiently. \\nLet\\'s get you set up! 🚀\\n\\n<Steps>\\n    <Step title=\"Install CrewAI\">\\n        Install CrewAI with all recommended tools using either method:\\n        ```shell Terminal\\n        pip install \\'crewai[tools]\\'\\n        ```\\n        or\\n        ```shell Terminal\\n        pip install crewai crewai-tools\\n        ```\\n\\n        <Note>\\n          Both methods install the core package and additional tools needed for most use cases.\\n        </Note>\\n    </Step>\\n\\n    <Step title=\"Upgrade CrewAI (Existing Installations Only)\">\\n        If you have an older version of CrewAI installed, you can upgrade it:\\n        ```shell Terminal\\n        pip install --upgrade crewai crewai-tools\\n        ```\\n\\n        <Warning>\\n            If you see a Poetry-related warning, you\\'ll need to migrate to our new dependency manager:\\n            ```shell Terminal\\n            crewai update\\n            ```\\n            This will update your project to use [UV](https://github.com/astral-sh/uv), our new faster dependency manager.\\n        </Warning>\\n\\n        <Note>\\n            Skip this step if you\\'re doing a fresh installation.\\n        </Note>\\n    </Step>\\n\\n    <Step title=\"Verify Installation\">\\n        Check your installed versions:\\n        ```shell Terminal\\n        pip freeze | grep crewai\\n        ```\\n\\n        You should see something like:\\n        ```markdown Output\\n        crewai==X.X.X\\n        crewai-tools==X.X.X\\n        ```\\n        <Check>Installation successful! You\\'re ready to create your first crew.</Check>\\n    </Step>\\n</Steps>\\n\\n# Creating a New Project\\n\\n<Info>\\n  We recommend using the YAML Template scaffolding for a structured approach to defining agents and tasks.\\n</Info>\\n\\n<Steps>\\n  <Step title=\"Generate Project Structure\">\\n    Run the CrewAI CLI command:\\n    ```shell Terminal\\n    crewai create crew <project_name>\\n    ```\\n\\n    This creates a new project with the following structure:\\n    <Frame>\\n    ```\\n    my_project/\\n    ├── .gitignore\\n    ├── pyproject.toml\\n    ├── README.md\\n    ├── .env\\n    └── src/\\n        └── my_project/\\n            ├── __init__.py\\n            ├── main.py\\n            ├── crew.py\\n            ├── tools/\\n            │   ├── custom_tool.py\\n            │   └── __init__.py\\n            └── config/\\n                ├── agents.yaml\\n                └── tasks.yaml\\n    ```\\n    </Frame>\\n  </Step>   \\n\\n  <Step title=\"Customize Your Project\">\\n    Your project will contain these essential files:\\n\\n    | File | Purpose |\\n    | --- | --- |\\n    | `agents.yaml` | Define your AI agents and their roles |\\n    | `tasks.yaml` | Set up agent tasks and workflows |\\n    | `.env` | Store API keys and environment variables |\\n    | `main.py` | Project entry point and execution flow |\\n    | `crew.py` | Crew orchestration and coordination |\\n    | `tools/` | Directory for custom agent tools |\\n\\n    <Tip>\\n      Start by editing `agents.yaml` and `tasks.yaml` to define your crew\\'s behavior.\\n      Keep sensitive information like API keys in `.env`.\\n    </Tip>\\n  </Step>\\n</Steps>\\n\\n## Next Steps\\n\\n<CardGroup cols={2}>\\n  <Card\\n    title=\"Build Your First Agent\"\\n    icon=\"code\"\\n    href=\"/quickstart\"\\n  >\\n    Follow our quickstart guide to create your first CrewAI agent and get hands-on experience.\\n  </Card>\\n  <Card\\n    title=\"Join the Community\"\\n    icon=\"comments\"\\n    href=\"https://community.crewai.com\"\\n  >\\n    Connect with other developers, get help, and share your CrewAI experiences.\\n  </Card>\\n</CardGroup>', mimetype='text/plain', start_char_idx=0, end_char_idx=3940, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_generator.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b261d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_length = len(dataset_generator.nodes) * num_questions_per_chunk\n",
    "questions_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "400c3dc4-3109-411c-87eb-2d130ff757a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:19<00:00, 19.89s/it]\n",
      "100%|██████████| 2/2 [00:51<00:00, 25.71s/it]\n",
      "100%|██████████| 2/2 [01:38<00:00, 49.44s/it]\n",
      "100%|██████████| 2/2 [02:05<00:00, 62.87s/it]\n",
      "100%|██████████| 2/2 [02:11<00:00, 65.80s/it] \n",
      "100%|██████████| 2/2 [02:11<00:00, 65.91s/it]\n",
      "100%|██████████| 2/2 [02:29<00:00, 74.52s/it] \n",
      "100%|██████████| 2/2 [00:41<00:00, 20.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# since there are 14 nodes, there should be a total of 28 questions\n",
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2052a43e-3a7a-4f0f-9f0c-7542ffbb64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are two questions as a Senior Programmer:</td>\n",
       "      <td>[---\\ntitle: Installation\\ndescription: Get st...</td>\n",
       "      <td>Here are the answers to the two questions:\\n\\n...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does CrewAI handle Python version requirem...</td>\n",
       "      <td>[---\\ntitle: Installation\\ndescription: Get st...</td>\n",
       "      <td>According to the provided context, CrewAI requ...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here are two questions as a Senior Programmer:</td>\n",
       "      <td>[---\\ntitle: Introduction\\ndescription: Build ...</td>\n",
       "      <td>Here are two answers to the queries based on t...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does CrewAI's Process component ensure smo...</td>\n",
       "      <td>[---\\ntitle: Introduction\\ndescription: Build ...</td>\n",
       "      <td>According to the provided documentation, the P...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here are two questions based on the context in...</td>\n",
       "      <td>[---\\ntitle: Quickstart\\ndescription: Build yo...</td>\n",
       "      <td>I'm ready to help. What are the two questions?</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can you modify the `agents.yaml` file to i...</td>\n",
       "      <td>[---\\ntitle: Quickstart\\ndescription: Build yo...</td>\n",
       "      <td>According to the provided context, any variabl...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Here are two potential questions as a Senior P...</td>\n",
       "      <td>[@crew\\n      def crew(self) -&gt; Crew:\\n       ...</td>\n",
       "      <td>Based on the provided code snippets and contex...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I add before and after kickoff functio...</td>\n",
       "      <td>[@crew\\n      def crew(self) -&gt; Crew:\\n       ...</td>\n",
       "      <td>To add before and after kickoff functions to y...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Here are two questions as a Senior Programmer:</td>\n",
       "      <td>[## 2. Benefits of AI Agents\\n    AI agents br...</td>\n",
       "      <td>I'm happy to help! However, I don't see any sp...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How would you implement the **Task Automation*...</td>\n",
       "      <td>[## 2. Benefits of AI Agents\\n    AI agents br...</td>\n",
       "      <td>Based on the provided context, it seems that t...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Here are two questions as a Senior Programmer:</td>\n",
       "      <td>[As we look toward the future, several anticip...</td>\n",
       "      <td>Based on the provided context, here are answer...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can I ensure consistency in naming convent...</td>\n",
       "      <td>[As we look toward the future, several anticip...</td>\n",
       "      <td>To ensure consistency in naming conventions be...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Here are two questions as a Senior Programmer:</td>\n",
       "      <td>[To use this feature, run.\\n\\n```shell\\ncrewai...</td>\n",
       "      <td>Here are my answers to the two questions:\\n\\n*...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How can I reset the memory of my crew before r...</td>\n",
       "      <td>[To use this feature, run.\\n\\n```shell\\ncrewai...</td>\n",
       "      <td>To reset the memory of your crew before runnin...</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "      <td>ai (llama3.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0      Here are two questions as a Senior Programmer:   \n",
       "1   How does CrewAI handle Python version requirem...   \n",
       "2      Here are two questions as a Senior Programmer:   \n",
       "3   How does CrewAI's Process component ensure smo...   \n",
       "4   Here are two questions based on the context in...   \n",
       "5   How can you modify the `agents.yaml` file to i...   \n",
       "6   Here are two potential questions as a Senior P...   \n",
       "7   How can I add before and after kickoff functio...   \n",
       "8      Here are two questions as a Senior Programmer:   \n",
       "9   How would you implement the **Task Automation*...   \n",
       "10     Here are two questions as a Senior Programmer:   \n",
       "11  How can I ensure consistency in naming convent...   \n",
       "12     Here are two questions as a Senior Programmer:   \n",
       "13  How can I reset the memory of my crew before r...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [---\\ntitle: Installation\\ndescription: Get st...   \n",
       "1   [---\\ntitle: Installation\\ndescription: Get st...   \n",
       "2   [---\\ntitle: Introduction\\ndescription: Build ...   \n",
       "3   [---\\ntitle: Introduction\\ndescription: Build ...   \n",
       "4   [---\\ntitle: Quickstart\\ndescription: Build yo...   \n",
       "5   [---\\ntitle: Quickstart\\ndescription: Build yo...   \n",
       "6   [@crew\\n      def crew(self) -> Crew:\\n       ...   \n",
       "7   [@crew\\n      def crew(self) -> Crew:\\n       ...   \n",
       "8   [## 2. Benefits of AI Agents\\n    AI agents br...   \n",
       "9   [## 2. Benefits of AI Agents\\n    AI agents br...   \n",
       "10  [As we look toward the future, several anticip...   \n",
       "11  [As we look toward the future, several anticip...   \n",
       "12  [To use this feature, run.\\n\\n```shell\\ncrewai...   \n",
       "13  [To use this feature, run.\\n\\n```shell\\ncrewai...   \n",
       "\n",
       "                                     reference_answer reference_answer_by  \\\n",
       "0   Here are the answers to the two questions:\\n\\n...       ai (llama3.1)   \n",
       "1   According to the provided context, CrewAI requ...       ai (llama3.1)   \n",
       "2   Here are two answers to the queries based on t...       ai (llama3.1)   \n",
       "3   According to the provided documentation, the P...       ai (llama3.1)   \n",
       "4      I'm ready to help. What are the two questions?       ai (llama3.1)   \n",
       "5   According to the provided context, any variabl...       ai (llama3.1)   \n",
       "6   Based on the provided code snippets and contex...       ai (llama3.1)   \n",
       "7   To add before and after kickoff functions to y...       ai (llama3.1)   \n",
       "8   I'm happy to help! However, I don't see any sp...       ai (llama3.1)   \n",
       "9   Based on the provided context, it seems that t...       ai (llama3.1)   \n",
       "10  Based on the provided context, here are answer...       ai (llama3.1)   \n",
       "11  To ensure consistency in naming conventions be...       ai (llama3.1)   \n",
       "12  Here are my answers to the two questions:\\n\\n*...       ai (llama3.1)   \n",
       "13  To reset the memory of your crew before runnin...       ai (llama3.1)   \n",
       "\n",
       "         query_by  \n",
       "0   ai (llama3.1)  \n",
       "1   ai (llama3.1)  \n",
       "2   ai (llama3.1)  \n",
       "3   ai (llama3.1)  \n",
       "4   ai (llama3.1)  \n",
       "5   ai (llama3.1)  \n",
       "6   ai (llama3.1)  \n",
       "7   ai (llama3.1)  \n",
       "8   ai (llama3.1)  \n",
       "9   ai (llama3.1)  \n",
       "10  ai (llama3.1)  \n",
       "11  ai (llama3.1)  \n",
       "12  ai (llama3.1)  \n",
       "13  ai (llama3.1)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f86d33ec-61b7-49a9-ab29-050a82088e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.save_json(\"rag_dataset.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
