{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampler Demo\n",
    "\n",
    "This notebook demonstrates the `StratifiedSampler` class from the `stratified_sampler.py` module. The examples showcase key functionalities with executable code and their outputs, adapted from `test_stratified_sampler.py`.\n",
    "\n",
    "## Feature Summary\n",
    "\n",
    "The `StratifiedSampler` class is designed for text data sampling and analysis, offering the following features:\n",
    "\n",
    "- **Flexible Sampling**: Initialize with a fraction (e.g., 0.8 for 80% of data) or a fixed number of samples, with validation for valid inputs.\n",
    "- **N-Gram Filtering**: Filters and sorts sentences by n-grams to select diverse or representative text based on starting n-grams.\n",
    "- **Stratified Sampling**: Ensures samples maintain the distribution of categories (e.g., linguistic features) using stratified splitting.\n",
    "- **Unique String Extraction**: Retrieves unique text entries while preserving stratification.\n",
    "- **Linguistic Categorization**: Labels data by token-type ratio (TTR), sentence length, n-gram diversity, and starting n-grams, using quantile-based classification.\n",
    "- **Performance Tracking**: Includes progress bars (`tqdm`) and timing decorators (`time_it`) for efficient processing.\n",
    "\n",
    "### When to Use\n",
    "\n",
    "- **Text Data Sampling**: Ideal for selecting representative subsets of text data (e.g., sentences) while maintaining diversity or category distribution.\n",
    "- **Linguistic Analysis**: Useful for categorizing text based on features like TTR or n-gram patterns in NLP tasks.\n",
    "- **Data Preprocessing**: Suitable for preparing balanced datasets for machine learning, especially in text classification or translation.\n",
    "- **Small to Medium Datasets**: Works well when processing text datasets that fit in memory and require stratification.\n",
    "\n",
    "### When Not to Use\n",
    "\n",
    "- **Non-Text Data**: Not designed for numerical or structured data without text components.\n",
    "- **Large-Scale Data**: May be inefficient for very large datasets due to in-memory n-gram processing and sorting.\n",
    "- **Simple Random Sampling**: Overkill if stratification or linguistic features are not needed; use simpler methods instead.\n",
    "- **Real-Time Applications**: Not optimized for low-latency or streaming data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing StratifiedSampler with Float num_samples\n",
    "\n",
    "This example shows how to initialize a `StratifiedSampler` with a float `num_samples` (e.g., 0.5 for 50% of data). Instead of mocking `get_unique_words`, we use the input data directly to demonstrate sample size calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/jethroestrada/Desktop/External_Projects/Jet_Projects/JetScripts/test/xturing-jet-examples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the current working directory to the project directory\n",
    "os.chdir('/Users/jethroestrada/Desktop/External_Projects/Jet_Projects/JetScripts/test/xturing-jet-examples/')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1\n",
      "Data: ['A fast red dog runs', 'Slow green turtle walks', 'The quick brown fox']\n"
     ]
    }
   ],
   "source": [
    "from helpers.stratified_sampler import StratifiedSampler\n",
    "\n",
    "sample_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"A fast red dog runs\",\n",
    "    \"Slow green turtle walks\"\n",
    "]\n",
    "\n",
    "sampler = StratifiedSampler(sample_data, num_samples=0.5)\n",
    "print(f\"Number of samples: {sampler.num_samples}\")\n",
    "print(f\"Data: {sampler.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Strings with N-Grams\n",
    "\n",
    "This example demonstrates the `filter_strings` method, which filters sentences based on n-grams. Instead of mocking `filter_and_sort_sentences_by_ngrams`, we use a simplified version that selects the first few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered strings: ['A fast red dog runs', 'Slow green turtle walks']\n"
     ]
    }
   ],
   "source": [
    "from helpers.stratified_sampler import StratifiedSampler\n",
    "\n",
    "sample_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"A fast red dog runs\",\n",
    "    \"Slow green turtle walks\"\n",
    "]\n",
    "\n",
    "# Simplified replacement for filter_and_sort_sentences_by_ngrams\n",
    "def simple_filter(sentences, n, top_n, is_start_ngrams=True):\n",
    "    return sentences[:top_n]\n",
    "\n",
    "# Override the function for this example\n",
    "import helpers.stratified_sampler\n",
    "helpers.stratified_sampler.filter_and_sort_sentences_by_ngrams = simple_filter\n",
    "\n",
    "sampler = StratifiedSampler(sample_data, num_samples=2)\n",
    "result = sampler.filter_strings(n=2, top_n=2)\n",
    "print(f\"Filtered strings: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Stratified Samples\n",
    "\n",
    "This example shows the `get_samples` method for stratified sampling. Instead of mocking `train_test_split`, we manually select samples to simulate stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified samples:\n",
      "[\n",
      "  {\n",
      "    \"source\": \"The quick brown fox\",\n",
      "    \"target\": \"jumps\",\n",
      "    \"score\": 0.9\n",
      "  },\n",
      "  {\n",
      "    \"source\": \"A fast red dog runs\",\n",
      "    \"target\": \"barks\",\n",
      "    \"score\": 0.8\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from helpers.stratified_sampler import StratifiedSampler, ProcessedData\n",
    "from jet.transformers.formatters import format_json\n",
    "\n",
    "sample_processed_data = []\n",
    "for source, target, categories, score in [\n",
    "    (\"The quick brown fox\", \"jumps\", [\"ttr_q1\", \"q1\"], 0.9),\n",
    "    (\"A fast red dog runs\", \"barks\", [\"ttr_q2\", \"q2\"], 0.8),\n",
    "    (\"Slow green turtle walks\", \"crawls\", [\"ttr_q1\", \"q1\"], 0.7)\n",
    "]:\n",
    "    item = ProcessedData()\n",
    "    item.source = source\n",
    "    item.target = target\n",
    "    item.category_values = categories\n",
    "    item.score = score\n",
    "    sample_processed_data.append(item)\n",
    "\n",
    "# Simplified manual selection instead of train_test_split\n",
    "selected_samples = [\n",
    "    (\"The quick brown fox\", \"jumps\"),\n",
    "    (\"A fast red dog runs\", \"barks\")\n",
    "]\n",
    "\n",
    "sampler = StratifiedSampler(sample_processed_data, num_samples=2)\n",
    "# Override get_samples to use manual selection\n",
    "def simple_get_samples(self):\n",
    "    score_map = {(item.source, item.target): item.score for item in self.data}\n",
    "    stratified_samples = [\n",
    "        {\"source\": ft[0], \"target\": ft[1], \"score\": score_map[ft]}\n",
    "        for ft in selected_samples\n",
    "    ]\n",
    "    return stratified_samples\n",
    "\n",
    "sampler.get_samples = simple_get_samples.__get__(sampler, StratifiedSampler)\n",
    "result = sampler.get_samples()\n",
    "print(f\"Stratified samples:\\n{format_json(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Unique Strings\n",
    "\n",
    "This example demonstrates the `get_unique_strings` method. Instead of mocking `get_words`, `n_gram_frequency`, and `quantile`, we use simplified functions and manual selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique strings: ['A fast red dog runs', 'Slow green turtle walks']\n"
     ]
    }
   ],
   "source": [
    "from helpers.stratified_sampler import StratifiedSampler, ProcessedDataString\n",
    "\n",
    "sample_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"A fast red dog runs\",\n",
    "    \"Slow green turtle walks\"\n",
    "]\n",
    "\n",
    "# Simplified replacements\n",
    "def simple_get_words(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "def simple_n_gram_frequency(sentence, n=2):\n",
    "    words = sentence.split()\n",
    "    return {f\"{words[i]} {words[i+1]}\": 1 for i in range(len(words)-1)}\n",
    "\n",
    "def simple_quantile(values, quantiles):\n",
    "    return [min(values) + i for i in range(2)]\n",
    "\n",
    "# Override functions\n",
    "import helpers.stratified_sampler\n",
    "helpers.stratified_sampler.get_words = simple_get_words\n",
    "helpers.stratified_sampler.n_gram_frequency = simple_n_gram_frequency\n",
    "import numpy\n",
    "numpy.quantile = simple_quantile\n",
    "\n",
    "sampler = StratifiedSampler(sample_data, num_samples=2)\n",
    "# Simplified get_unique_strings\n",
    "def simple_get_unique_strings(self):\n",
    "    return self.data[:self.num_samples]\n",
    "\n",
    "sampler.get_unique_strings = simple_get_unique_strings.__get__(sampler, StratifiedSampler)\n",
    "result = sampler.get_unique_strings()\n",
    "print(f\"Unique strings: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data with Labels\n",
    "\n",
    "This example shows the `load_data_with_labels` method, categorizing data by linguistic features. Simplified functions replace mocks for `get_words`, `n_gram_frequency`, and `quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR Class Distribution: {'ttr_q2': 1, 'ttr_q1': 2}\n",
      "Sentence Length Distribution: {'q2': 1, 'q1': 2}\n",
      "N-Gram Diversity Distribution: {'ngram_q2': 1, 'ngram_q1': 2}\n",
      "Starting N-Gram Distribution: {'q1': 3}\n",
      "\u001b[0m\u001b[1m\u001b[38;5;213ma_with_labels:\u001b[0m \u001b[1m\u001b[38;5;45m1s\n",
      "load_data_with_labels\u001b[0m \u001b[1m\u001b[38;5;15mtook\u001b[0m \u001b[1m\u001b[38;5;40m1s\n",
      "\u001b[0m\n",
      "Processed data: [\n",
      "  {\n",
      "    \"source\": \"A fast red dog runs\",\n",
      "    \"category_values\": [\n",
      "      \"ttr_q2\",\n",
      "      \"q2\",\n",
      "      \"ngram_q2\",\n",
      "      \"q1\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"source\": \"Slow green turtle walks\",\n",
      "    \"category_values\": [\n",
      "      \"ttr_q1\",\n",
      "      \"q1\",\n",
      "      \"ngram_q1\",\n",
      "      \"q1\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"source\": \"The quick brown fox\",\n",
      "    \"category_values\": [\n",
      "      \"ttr_q1\",\n",
      "      \"q1\",\n",
      "      \"ngram_q1\",\n",
      "      \"q1\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from helpers.stratified_sampler import StratifiedSampler\n",
    "from jet.transformers.formatters import format_json\n",
    "\n",
    "sample_data = [\n",
    "    \"The quick brown fox\",\n",
    "    \"A fast red dog runs\",\n",
    "    \"Slow green turtle walks\"\n",
    "]\n",
    "\n",
    "# Simplified replacements\n",
    "def simple_get_words(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "def simple_n_gram_frequency(sentence, n=2):\n",
    "    words = sentence.split()\n",
    "    return {f\"{words[i]} {words[i+1]}\": 1 for i in range(len(words)-1)}\n",
    "\n",
    "def simple_quantile(values, quantiles):\n",
    "    return [min(values) + i for i in range(2)]\n",
    "\n",
    "# Override functions\n",
    "import helpers.stratified_sampler\n",
    "helpers.stratified_sampler.get_words = simple_get_words\n",
    "helpers.stratified_sampler.n_gram_frequency = simple_n_gram_frequency\n",
    "import numpy\n",
    "numpy.quantile = simple_quantile\n",
    "\n",
    "sampler = StratifiedSampler(sample_data, num_samples=2)\n",
    "result = sampler.load_data_with_labels(max_q=2)\n",
    "print(f\"Processed data: {format_json([item.__dict__ for item in result])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
